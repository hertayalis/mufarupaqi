<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Sixteen Tesla V100s, 30 TB of NVMe, only $400K -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="Ever wondered why the consumer GPU market is not getting much love from NVIDIA’s Volta architecture yet? This is a minefield of a question, nuanced by many different viewpoints and angles – even asking the question will poke the proverbial hornet nest inside my own mind of different possibilities. Here is one angle to consider: NVIDIA is currently loving the data center, and the deep learning market, and making money hand-over-fist."><meta name=author content="Reinaldo Massengill"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="Sixteen Tesla V100s, 30 TB of NVMe, only $400K"><meta property="og:description" content="Ever wondered why the consumer GPU market is not getting much love from NVIDIAs Volta architecture yet? This is a minefield of a question, nuanced by many different viewpoints and angles  even asking the question will poke the proverbial hornet nest inside my own mind of different possibilities. Here is one angle to consider:"><meta property="og:type" content="article"><meta property="og:url" content="/nvidias-dgx2-sixteen-v100-gpus-30-tb-of-nvme-only-400k.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-09-01T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-01T00:00:00+00:00"><meta itemprop=name content="Sixteen Tesla V100s, 30 TB of NVMe, only $400K"><meta itemprop=description content="Ever wondered why the consumer GPU market is not getting much love from NVIDIAs Volta architecture yet? This is a minefield of a question, nuanced by many different viewpoints and angles  even asking the question will poke the proverbial hornet nest inside my own mind of different possibilities. Here is one angle to consider:"><meta itemprop=datePublished content="2024-09-01T00:00:00+00:00"><meta itemprop=dateModified content="2024-09-01T00:00:00+00:00"><meta itemprop=wordCount content="753"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Sixteen Tesla V100s, 30 TB of NVMe, only $400K"><meta name=twitter:description content="Ever wondered why the consumer GPU market is not getting much love from NVIDIAs Volta architecture yet? This is a minefield of a question, nuanced by many different viewpoints and angles  even asking the question will poke the proverbial hornet nest inside my own mind of different possibilities. Here is one angle to consider:"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>ZedVlog</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><time>Sep 1, 2024</time>
<span>Reinaldo Massengill</span></p><h1>Sixteen Tesla V100s, 30 TB of NVMe, only $400K</h1></header><section class=post-content><p>Ever wondered why the consumer GPU market is not getting much love from NVIDIA’s Volta architecture yet? This is a minefield of a question, nuanced by many different viewpoints and angles – even asking the question will poke the proverbial hornet nest inside my own mind of different possibilities. Here is one angle to consider: NVIDIA is currently loving the data center, and the deep learning market, and making money hand-over-fist. The Volta architecture, with CUDA Tensor cores, is unleashing high performance to these markets, and the customers are willing to pay for it. So introduce the latest monster from NVIDIA: the DGX-2.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12587/screenshot_61_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>DGX-2 builds upon DGX-1 in several ways. Firstly, it introduces NVIDIA’s new NVSwitch, enabling 300 GB/s chip-to-chip communication at 12 times the speed of PCIe. This, with NVLink2, enables sixteen GPUs to be grouped together in a single system, for a total bandwidth going beyond 14 TB/s. Add in a pair of Xeon CPUs, 1.5 TB of memory, and 30 TB of NVMe storage, and we get a system that consumes 10 kW, weighs 350 lbs, but offers easily double the performance of the DGX-1. NVIDIA likes to tout that this means it offers a total of ~2 PFLOPs of compute performance in a single system, when using the tensor cores.</p><table border=0 width=85%><tbody readability=7><tr readability=2><td class=contentwhite colspan=3>NVIDIA DGX Series (with Volta)</td></tr><tr class=tlblue><td>&nbsp;</td><td>DGX-2</td><td>DGX-1</td></tr><tr readability=2><td class=tlgrey>CPUs</td><td><strong>2 x Intel Xeon<br>Platinum</strong></td><td>2 x Intel Xeon<br>E5-2600 v4</td></tr><tr readability=4><td class=tlgrey>GPUs</td><td><strong>16 x NVIDIA Tesla V100<br>32GB HBM2</strong></td><td>8 x NVIDIA Tesla V100<br>16 GB HBM2</td></tr><tr><td class=tlgrey>System Memory</td><td><strong>Up to 1.5 TB DDR4</strong></td><td>Up to 0.5 TB DDR4</td></tr><tr><td class=tlgrey>GPU Memory</td><td><strong>512 GB HBM2<br>(16 x 32 GB)</strong></td><td>256 GB HBM<br>(8 x 32 GB)</td></tr><tr><td class=tlgrey>Storage</td><td><strong>30 TB NVMe</strong><br>Up to 60 TB</td><td>4 x 1.92 TB NVMe</td></tr><tr readability=2><td class=tlgrey>Networking</td><td><strong>8 x Infiniband or<br>8 x 100 GbE</strong></td><td>4 x IB +<br>2 x 10 GbE</td></tr><tr><td class=tlgrey>Power</td><td><strong>10 kW</strong></td><td>3.5 kW</td></tr><tr><td class=tlgrey>Size</td><td><strong>350 lbs</strong></td><td>134 lbs</td></tr><tr readability=4><td class=tlgrey>GPU Throughput</td><td><strong>Tensor: 1920 TFLOPs</strong><br>FP16: 480 TFLOPs<br>FP32: 240 TFLOPs<br>FP64: 120 TFLOPs</td><td>Tensor: 960 TFLOPs<br>FP16: 240 TFLOPs<br>FP32: 120 TFLOPs<br>FP64: 60 TFLOPs</td></tr><tr><td class=tlgrey>Cost</td><td><strong>$399,000</strong></td><td>$149,000</td></tr></tbody></table><p><span>NVIDIA’s overall topology relies on a dual stacked system. The high level concept photo provided indicates that there are actually 12 NVSwitches (216 ports) in the system in order to maximize the amount of bandwidth available between the GPUs. With 6 ports per Tesla V100 GPU, each running in the larger 32GB of HBM2 configuration, this means that the Teslas alone would be taking up 96 of those ports if NVIDIA has them fully wired up to maximize individual GPU bandwidth within the topology.</span></p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12587/screenshot_69_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><br>AlexNET, the network that 'started' the latest machine learning revolution, now takes 18 minutes</p><p>Notably here, the topology of the DGX-2 means that all 16 GPUs are able to pool their memory into a unified memory space, though with the usual tradeoffs involved if going off-chip. Not unlike the Tesla V100 memory capacity increase then, one of NVIDIA’s goals here is to build a system that can keep in-memory workloads that would be too large for an 8 GPU cluster. Providing one such example, NVIDIA is saying that the DGX-2 is able to complete the training process for FAIRSEQ – a neural network model for language translation – 10x faster than a DGX-1 system, bringing it down to less than two days total rather than 15.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12587/screenshot_58_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Otherwise, similar to its DGX-1 counterpart, the DGX-2 is designed to be a powerful server in its own right. Exact specifications are still TBD, but NVIDIA has already told us that it’s based around a pair of Xeon Platinum CPUs, which in turn can be paired with up to 1.5TB of RAM. On the storage side the DGX-2 comes with 30TB of NVMe-based solid state storage, which can be further expanded to 60TB. And for clustering or further inter-system communications, it also offers InfiniBand and 100GigE connectivity, up to eight of them.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/12587/nvlink20_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The new NVSwitches means that the PCIe lanes of the CPUs can be redirected elsewhere, most notably towards storage and networking connectivity.</p><p>Ultimately the DGX-2 is being pitched at an even higher-end segment of the deep-learning market than the DGX-1 is. Pricing for the system runs at $400k, rather than the $150k for the original DGX-1. For more than double the money, the user gets Xeon Platinums (rather than v4), double the V100 GPUs each with double the HBM2, triple the DRAM, and 15x the NVMe storage by default.</p><p>NVIDIA has stated that DGX-2 is already certified for the major cloud providers.</p><h3>Related Reading</h3><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5zgZdwZqeumZm2or%2BMnZ6xal2otrnAxJ6lZq5hZX1us8%2BuqmZrYGLBo3nOn2Snrp2aerC6y7JkbWhgoA%3D%3D</p></section><nav class=post-nav><a class=prev href=./sid-rosenberg-net-worth-income-salary-earnings-biography-how-much-money-make-html.html><span>←</span><span>Sid Rosenberg Net Worth, Income, Salary, Earnings, Biography, How much money make?</span></a>
<a class=next href=./intel-core-i710700-vs-core-i710700k-review-is-65w-comet-lake-an-option.html><span>Gaming Tests: Civilization 6 - Intel Core i7-10700 vs Core i7-10700K Review: Is 65W Comet Lake an Op</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>